What are the main challenges you foresee in adapting to the AI ​​Act?,Do you have suggestions for how the AI ​​Act could be improved to facilitate the adoption by companies like yours?,How will the AI ​​Act affect software development processes?,How do you plan to address the algorithmic transparency requirements imposed by the AI ​​Act?,How will the AI ​​Act affect your data management and data governance practices?,How will the AI ​​Act affect your AI model testing and validation practices?,What technical challenges does the AI ​​Act present for implementing transparent and explainable AI systems?
,Cooperation between companies,More controls and documentation,More R&D,More security,A larger set of competencies required,"It’ more a matter of process, than technology"
"rom a strategic perspective, the primary challenges include adapting Data Governance processes—encompassing dataset traceability, quality assurance, and bias mitigation—implementing robustness and fairness metrics throughout the model lifecycle, and producing certifiable technical documentation. In addition, the search for talent with interdisciplinary expertise (legal, ethical, and technological) and the need to collaborate with regulatory authorities, industry standards bodies (e.g., ISO/IEC), and consortium-based initiatives (such as Gaia-X) represent critical hurdles that must be addressed. Finally, continuous model review and reputational risk management will become central components of the new regulatory landscape.","Greater Clarity and Practical Guidance:
Provide detailed technical guidelines and dynamic updates that can keep pace with rapid technological advancements (e.g., foundation models and quantum-enhanced AI), ensuring that the legislation remains relevant and not rendered obsolete as innovation progresses.


Regulatory Sandbox Ecosystems:
Establish controlled environments where innovative AI solutions can be tested under a regulated yet flexible framework, thereby streamlining the compliance process and reducing the risk of unintentional regulatory breaches.


SME Support:
Allocate funding and resources to assist small and medium-sized enterprises in acquiring the necessary tools and skills for compliance, preventing market dominance by a few large players and fostering a more competitive and diverse AI ecosystem.


Public-Private Synergy:
Foster collaborations among academia, industry, and policymakers, integrating cutting-edge research with operational best practices. This alignment ensures that the regulatory framework remains closely attuned to actual market needs and promotes a healthier, more sustainable innovation environment.","The Act will likely embed regulatory constraints directly into our software development lifecycle, influencing both workflows and tooling. We expect to integrate automated compliance checks into continuous integration/continuous delivery (CI/CD) pipelines, adopt code scanning tools designed to detect potential non-compliance (e.g., unfair features, biased training sets), and refine our documentation practices to produce traceable model cards and version-controlled metadata. Additionally, development roadmaps will need to accommodate more iterative testing phases, including fairness evaluations, adversarial robustness checks, and periodic compliance audits, effectively merging regulatory considerations with traditional DevOps and MLOps routines.","We intend to leverage a combination of model explainability tools (e.g., LIME, SHAP), standardized transparency reports (e.g., model cards, data sheets for datasets), and continuous monitoring frameworks that log prediction rationales over time. Our approach will also include adopting architectural patterns that allow “explainability-by-design,” ensuring that models are accompanied by interpretable surrogate models or rule-based systems that can provide human-understandable insights. Furthermore, we may partner with specialized vendors or open-source communities that provide advanced interpretability libraries, and implement clear internal guidelines for presenting model decisions to stakeholders and auditors.","While we welcome the focus on explainability, it introduces non-trivial technical and conceptual challenges. Highly complex architectures such as deep neural networks or transformer-based language models are often considered “black boxes,” making it difficult to derive simple, intuitive explanations. Meeting these requirements will demand significant R&D to refine model structures, incorporate attention mechanisms that are more inherently interpretable, and invest in explainable AI frameworks that produce meaningful insights without overly constraining performance. Nonetheless, we view this as an opportunity to differentiate ourselves by delivering ethically sound and transparent solutions.","We will strengthen our data management protocols by introducing comprehensive version control of datasets, automated metadata generation, and well-defined data retention policies. Data governance frameworks will incorporate periodic bias and fairness assessments, more thorough data quality checks, and increased documentation around data origin, preprocessing steps, and intended usage scenarios. This enhanced data stewardship ensures every dataset feeding into our AI models can be scrutinized for compliance at any time, fostering trust and accountability throughout the data lifecycle.","Complexity of Interpretability: Many state-of-the-art models are inherently opaque, and making them explainable without losing performance is non-trivial.
Integration Overhead: Incorporating explainability modules, bias detection tools, and compliance logging within existing production architectures requires careful engineering.
Scalability of Validation: Continuous compliance monitoring and explainability checks at scale may increase computational overhead and infrastructure costs.
Standardization Gaps: The lack of universally accepted metrics or protocols for “sufficient” explainability makes it challenging to define and verify compliance targets consistently."
Speed of adoption,,"Limited, data and data governance is the key aspect for AI",,Immense impact,More disciple to improve quality,
"Big tech companies will invest a lot of money to find ways to circumvent (at least some of) the constraints posed by the AI Act, just like they already do with taxes. This will pose a challenge to smaller companies.",,,,,,
block innovation and investment,"clearer communications and online tools to be compliant, rather than shitty papers to fill",,not yet assessed,will stop doing business in the EU,,
Security and define an ex-ante unique AI system scope,Concrete framework to follow or adopt,"More verification, more focus on the development of explanation algorithms or documentation, traceability",Compiling Data Cards and Model Cards for each model with in-depth descriptions of the data and algorithm,More focus on anonymisation and management of data versions,Testing no longer based only on mathematical performance but also on explainability criteria,"For some systems it will be very complex to arrive at an explicability, but it will be necessary to do that"
Plan a possible audit done by external agencies,,Documentation must be perfect,Plan explainabilty as base result for any training,More control structures and enlarged delivery times,A proper infrastructure must be present,Data anonimization
"I believe the main challenge will be to establish appropriate regulations in a field like Artificial Intelligence, where new technologies and use cases emerge daily. It is crucial to ensure individual privacy while also avoiding unnecessary obstacles to the opportunities presented by this rapidly evolving field.",I think it is important to give clear and transparent regulations; only in this case everybody will have the chance of implementing the new regulations in the most efficient way.,The new architecture needs to be redesigned in a privacy-preserving way. Although this new approach won't be too expensive.,I don't have though about this problem yet.,We will surely needs more effective ways of data management,"I will redesign the testing pipeline, including a privacy-aware approach.",Most of AI system aren't truly explainable due to their nature
We need to keep all AI logs results (End-to-End Train / Test) to facilitate with AI Act,This is required to redesign again to make it new version and more transparent.,"Not much, This is like releasing new version of Software.","algorithmic transparency is to start with minimum 94 days data for training and test as sample, once all team verify then make it on full data.","Before there is no documentation required for major update, now it is required to compile more.",Double sample Testing & Validation  required.,Required more computing power and resouces
"ensuring transparency and explainability, aligning cross-functional teams, integrating AI Act compliance into existing processes",,"The AI Act will significantly impact software development processes, in many ways. Developers will need to integrate compliance checks into every stage of the software","We will prioritize non-AI solutions where feasible. If compliance with transparency requirements is too complex or unachievable, the project will be discontinued.",I don't know,I don't know,"as certain technologies, such as complex neural networks and advanced LLMs, are inherently non-explainable. This will effectively exclude a portion of the technological options available, limiting the use of high-performing but opaque models in regulated applications"
Inhibitions to develop AI for high risk applications,AI act in the sense is good for companies like us develop algorithms in compliance to regulatory acts,,make algorithm explainable,Cautious in data collection and preparation,no,training related to that